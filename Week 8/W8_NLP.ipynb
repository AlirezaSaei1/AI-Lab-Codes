{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing\n",
    "- Language Models\n",
    "- N-grams\n",
    "- Embedding\n",
    "- why not MLP?\n",
    "- RNNs\n",
    "    - GRU\n",
    "    - LSTM\n",
    "- Vanishing / Exploding Gradient:\n",
    "    - RNN does not have different behaviors with words (it either forgets all or remembers all)\n",
    "- Attention Mechanism\n",
    "- Transformer (Attention is all you need (no need for RNN))\n",
    "    - Does not consider sequences but uses \"Positional Encoding\"\n",
    "- BERT: Encoder only transformer (pretrained / Can be fine-tuned) -> Extracts text features like ResNet and VGG in Images\n",
    "    1. Masked Language Model (MLM) Loss\n",
    "    2. Next Sentence Prediction (NSP) Loss\n",
    "- LLMs\n",
    "    - GPT3 -> Decoder Only + Positional Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
