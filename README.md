# AI Lab Course Repository

Welcome to the repository for AI Lab Course at University of Isfahan. This repository contains all the code and resources used throughout the AI lab course. Each week focuses on different aspects of AI, ranging from classical machine learning techniques to advanced deep learning models and natural language processing.

## Table of Contents
- [Week 1: Classification](#week-1-classification)
- [Week 2: Clustering](#week-2-clustering)
- [Week 3 and 4: Deep Learning with PyTorch](#week-3-and-4-deep-learning-with-pytorch)
- [Week 5: Image Processing](#week-5-image-processing)
- [Week 6: Object Detection](#week-6-object-detection)
- [Week 7: Road Sign Detection](#week-7-road-sign-detection)
- [Week 8: Fundamentals of NLP](#week-8-fundamentals-of-nlp)
- [Week 9: Text Classification](#week-9-text-classification)
- [Week 10: Speech to Text with Wav2Vec](#week-10-speech-to-text-with-wav2vec)

## Week 1: Classification

In the first week, we explored various classification algorithms on the penguin sizes dataset. The algorithms used include:
- Support Vector Machine (SVM)
- K-Nearest Neighbors (KNN)
- Random Forest (RF)
- Naive Bayes (NB)

The goal was to understand the basics of classification and compare the performance of different algorithms.

## Week 2: Clustering

During the second week, we performed image segmentation through clustering. The task involved clustering an image to segment different regions. This exercise provided insight into unsupervised learning and image processing techniques.

## Week 3 and 4: Deep Learning with PyTorch

Over weeks 3 and 4, we delved into deep learning using PyTorch. The key activities included:
- Building a custom dataset and dataloader
- Training a neural network model
- Evaluating the model's performance

These exercises helped in understanding the workflow of deep learning projects and the use of PyTorch as a deep learning framework.

## Week 5: Image Processing

In the fifth week, we focused on image processing techniques. The main topics covered were:
- Color spaces
- Thresholding
- ...

These fundamental techniques are crucial for preprocessing images in computer vision tasks in future weeks.

## Week 6: Object Detection

Week 6 was dedicated to an object detection task. The objective was to detect and mark red balls in a video of bouncing balls with different colors. This task provided practical experience in object detection and video processing.

## Week 7: Road Sign Detection

In the seventh week, we used YOLOv8, a state-of-the-art object detection model, to detect road signs. The model was trained on a custom dataset of road signs, demonstrating the application of deep learning in real-world scenarios.

## Week 8: Fundamentals of NLP

The eighth week introduced the fundamentals and basics of Natural Language Processing (NLP). Topics covered include:
- Language Models
- N-grams
- Recurrent Neural Networks (RNNs)
- Gated Recurrent Unit (GRU)
- Long Short-Term Memory (LSTM)
- Attention Mechanism
- Transformer (Attention is all you need)
- BERT: Encoder-only transformer
- Large Language Models (LLMs)

These concepts are fundamental to understanding modern NLP techniques and architectures.

## Week 9: Text Classification

In the final week, we built a text classifier for emails to categorize them as positive, negative, or mixed sentiments. We used BERT tokenizer and `BertForSequenceClassification` for this task, leveraging pre-trained models for efficient text classification.

## Week 10: Speech to Text with Wav2Vec

In the tenth week, we explored speech recognition using Wav2Vec 2.0. The activities included:
- Loading the audio data
- Utilizing the Wav2Vec 2.0 model for speech-to-text conversion
- Evaluating the model's performance on an audio samples
- Plot Signal, FFT, and MFCC Forms of it

This week demonstrated the application of deep learning models in converting spoken language into written text, showcasing advancements in automatic speech recognition (ASR) technologies.

## Week 11: Stay Tuned!
